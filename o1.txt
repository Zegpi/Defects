Start of PruebaV5S 
Current time is 21:09:56 

 System for Initialization for S starting 

IGA: dim=2 dof=8 order=1 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[1,0] rule=LEGENDRE[2] periodic=0 nnp=202 nel=201
Axis 1: basis=BSPLINE[1,0] rule=LEGENDRE[2] periodic=0 nnp=202 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=40804 min=6767 max=6868 max/min=1.01493
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for curl part of Helmholtz of S starting 

IGA: dim=2 dof=8 order=1 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[1,0] rule=LEGENDRE[2] periodic=0 nnp=202 nel=201
Axis 1: basis=BSPLINE[1,0] rule=LEGENDRE[2] periodic=0 nnp=202 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=40804 min=6767 max=6868 max/min=1.01493
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for grad part of Helmholtz of S starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Axis 1: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41209 min=6767 max=7038 max/min=1.04005
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for L2 projection for Alfa+Sp:X starting 

IGA: dim=2 dof=2 order=1 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[1,0] rule=LEGENDRE[2] periodic=0 nnp=202 nel=201
Axis 1: basis=BSPLINE[1,0] rule=LEGENDRE[2] periodic=0 nnp=202 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=40804 min=6767 max=6868 max/min=1.01493
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 8.224640397984e-01 
  1 KSP Residual norm 1.152295415682e-01 
  2 KSP Residual norm 2.389379677977e-02 
  3 KSP Residual norm 3.736493547550e-03 
  4 KSP Residual norm 5.579398760660e-07 
  5 KSP Residual norm 6.153637477793e-08 
  6 KSP Residual norm 3.867759911749e-15 
  7 KSP Residual norm 2.734913629317e-15 
  8 KSP Residual norm 2.233046789321e-15 
  9 KSP Residual norm 1.933874282935e-15 
 10 KSP Residual norm 1.729709312151e-15 
 11 KSP Residual norm 1.579001062625e-15 
 12 KSP Residual norm 1.461870737044e-15 
 13 KSP Residual norm 1.367454730532e-15 
 14 KSP Residual norm 1.289248588726e-15 
 15 KSP Residual norm 1.223088530916e-15 
 16 KSP Residual norm 1.166169101207e-15 
 17 KSP Residual norm 1.116521864759e-15 
 18 KSP Residual norm 1.072719472767e-15 
 19 KSP Residual norm 1.033698318813e-15 
 20 KSP Residual norm 9.986474267085e-16 
 21 KSP Residual norm 9.669361916766e-16 
 22 KSP Residual norm 9.380658761410e-16 
 23 KSP Residual norm 9.116361504919e-16 
 24 KSP Residual norm 8.873214575298e-16 
 25 KSP Residual norm 8.648539643293e-16 
 26 KSP Residual norm 8.440110361963e-16 
 27 KSP Residual norm 8.246058802238e-16 
 28 KSP Residual norm 8.064804522032e-16 
 29 KSP Residual norm 7.895000070443e-16 
 30 KSP Residual norm 3.760770918623e-15 
 31 KSP Residual norm 5.407970343363e-16 
 32 KSP Residual norm 1.050374818261e-16 
 33 KSP Residual norm 2.186543679674e-17 
 34 KSP Residual norm 3.458408276602e-19 
 35 KSP Residual norm 1.136173111135e-20 
 36 KSP Residual norm 1.622550479579e-30 
Linear solve converged due to CONVERGED_RTOL iterations 36
KSP Object: 6 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-25, absolute=1e-40, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=13534, cols=13534, bs=2
            package used to perform factorization: petsc
            total: nonzeros=239596, allocated nonzeros=239596
            total number of mallocs used during MatSetValues calls=0
                block size is 2
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=13534, cols=13534, bs=2
      total: nonzeros=239596, allocated nonzeros=239596
      total number of mallocs used during MatSetValues calls=0
          block size is 2
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=81608, cols=81608, bs=2
    total: nonzeros=1459264, allocated nonzeros=1459264
    total number of mallocs used during MatSetValues calls=0

 System for curl part of Helmholtz of Up starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Axis 1: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41209 min=6767 max=7038 max/min=1.04005
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for Z0 starting 

IGA: dim=2 dof=2 order=3 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for Stress starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 2.141715661715e+01 
  1 KSP Residual norm 4.519006295412e+00 
  2 KSP Residual norm 1.075251129208e+00 
  3 KSP Residual norm 1.883397632786e-02 
  4 KSP Residual norm 8.868638749036e-03 
  5 KSP Residual norm 3.193419699347e-03 
  6 KSP Residual norm 7.597786213284e-05 
  7 KSP Residual norm 7.991359517481e-06 
  8 KSP Residual norm 2.217541799770e-06 
  9 KSP Residual norm 1.686385074251e-06 
 10 KSP Residual norm 6.502527863989e-07 
 11 KSP Residual norm 1.599699227688e-07 
 12 KSP Residual norm 2.947865357154e-10 
 13 KSP Residual norm 1.225555973412e-10 
 14 KSP Residual norm 3.293906053428e-11 
 15 KSP Residual norm 3.544947784110e-12 
 16 KSP Residual norm 9.409302040385e-14 
 17 KSP Residual norm 6.650179396451e-14 
 18 KSP Residual norm 5.429023997513e-14 
 19 KSP Residual norm 4.701305999366e-14 
 20 KSP Residual norm 4.204780391181e-14 
 21 KSP Residual norm 3.838302660099e-14 
 22 KSP Residual norm 3.553498996321e-14 
 23 KSP Residual norm 3.323938692394e-14 
 24 KSP Residual norm 3.133798940347e-14 
 25 KSP Residual norm 2.972951968392e-14 
 26 KSP Residual norm 2.834574497215e-14 
 27 KSP Residual norm 2.713879327041e-14 
 28 KSP Residual norm 2.607395361635e-14 
 29 KSP Residual norm 2.512536190544e-14 
 30 KSP Residual norm 4.808080902002e-13 
 31 KSP Residual norm 6.723359268688e-14 
 32 KSP Residual norm 2.674419309748e-14 
 33 KSP Residual norm 1.425212469818e-14 
 34 KSP Residual norm 2.338165070303e-15 
 35 KSP Residual norm 1.461112652161e-15 
 36 KSP Residual norm 1.179705516557e-15 
 37 KSP Residual norm 3.088400875638e-16 
 38 KSP Residual norm 1.433809691669e-17 
 39 KSP Residual norm 3.116689328232e-18 
 40 KSP Residual norm 1.427125649871e-18 
 41 KSP Residual norm 2.025977331750e-20 
 42 KSP Residual norm 7.243382300856e-21 
 43 KSP Residual norm 1.817080138790e-22 
 44 KSP Residual norm 3.012529004204e-24 
Linear solve converged due to CONVERGED_RTOL iterations 44
KSP Object: 6 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-24, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=27068, cols=27068, bs=4
            package used to perform factorization: petsc
            total: nonzeros=5081840, allocated nonzeros=5081840
            total number of mallocs used during MatSetValues calls=0
                block size is 4
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=27068, cols=27068, bs=4
      total: nonzeros=5081840, allocated nonzeros=5081840
      total number of mallocs used during MatSetValues calls=0
          block size is 4
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=166464, cols=166464, bs=4
    total: nonzeros=32080896, allocated nonzeros=32080896
    total number of mallocs used during MatSetValues calls=0

 System for Classic Stress starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 2.275106757169e+01 
  1 KSP Residual norm 6.114859915999e+00 
  2 KSP Residual norm 1.865922375963e+00 
  3 KSP Residual norm 2.052958660636e-02 
  4 KSP Residual norm 8.942731336188e-03 
  5 KSP Residual norm 4.392908426946e-03 
  6 KSP Residual norm 1.604797721207e-04 
  7 KSP Residual norm 1.483389826671e-05 
  8 KSP Residual norm 2.683004545364e-06 
  9 KSP Residual norm 1.219617476248e-06 
 10 KSP Residual norm 3.854021976352e-07 
 11 KSP Residual norm 1.584065971147e-07 
 12 KSP Residual norm 1.402067524289e-10 
 13 KSP Residual norm 8.329416028832e-11 
 14 KSP Residual norm 4.776749243190e-11 
 15 KSP Residual norm 1.379622012641e-12 
 16 KSP Residual norm 8.477628668921e-14 
 17 KSP Residual norm 6.002620869837e-14 
 18 KSP Residual norm 4.903534097445e-14 
 19 KSP Residual norm 4.247553664406e-14 
 20 KSP Residual norm 3.799659234718e-14 
 21 KSP Residual norm 3.468920409147e-14 
 22 KSP Residual norm 3.211809420393e-14 
 23 KSP Residual norm 3.004522171214e-14 
 24 KSP Residual norm 2.832800357858e-14 
 25 KSP Residual norm 2.687513642939e-14 
 26 KSP Residual norm 2.562508671189e-14 
 27 KSP Residual norm 2.453467093648e-14 
 28 KSP Residual norm 2.357257073226e-14 
 29 KSP Residual norm 2.271544558054e-14 
 30 KSP Residual norm 4.921531288075e-13 
 31 KSP Residual norm 5.082544673564e-14 
 32 KSP Residual norm 2.823697181232e-14 
 33 KSP Residual norm 1.774854123732e-14 
 34 KSP Residual norm 1.104845070088e-15 
 35 KSP Residual norm 8.376233821485e-16 
 36 KSP Residual norm 4.579197710940e-16 
 37 KSP Residual norm 1.699240635135e-16 
 38 KSP Residual norm 1.254522461425e-17 
Linear solve converged due to CONVERGED_RTOL iterations 38
KSP Object: 6 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-18, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=27068, cols=27068, bs=4
            package used to perform factorization: petsc
            total: nonzeros=5081840, allocated nonzeros=5081840
            total number of mallocs used during MatSetValues calls=0
                block size is 4
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=27068, cols=27068, bs=4
      total: nonzeros=5081840, allocated nonzeros=5081840
      total number of mallocs used during MatSetValues calls=0
          block size is 4
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=166464, cols=166464, bs=4
    total: nonzeros=32080896, allocated nonzeros=32080896
    total number of mallocs used during MatSetValues calls=0

 System for CoupleStress starting 

IGA: dim=2 dof=2 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for Ue starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 3.918987600954e+00 
  1 KSP Residual norm 1.048968448196e+00 
  2 KSP Residual norm 3.190937876955e-01 
  3 KSP Residual norm 3.920975798530e-03 
  4 KSP Residual norm 1.820414792778e-03 
  5 KSP Residual norm 8.140459389056e-04 
  6 KSP Residual norm 2.851844576492e-05 
  7 KSP Residual norm 2.580765762843e-06 
  8 KSP Residual norm 5.603483592717e-07 
  9 KSP Residual norm 3.391329166402e-07 
 10 KSP Residual norm 1.554932490351e-07 
 11 KSP Residual norm 3.649094647260e-08 
 12 KSP Residual norm 5.271309908025e-11 
Linear solve converged due to CONVERGED_RTOL iterations 12
KSP Object: 6 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-10, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=27068, cols=27068, bs=4
            package used to perform factorization: petsc
            total: nonzeros=5081840, allocated nonzeros=5081840
            total number of mallocs used during MatSetValues calls=0
                block size is 4
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=27068, cols=27068, bs=4
      total: nonzeros=5081840, allocated nonzeros=5081840
      total number of mallocs used during MatSetValues calls=0
          block size is 4
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=166464, cols=166464, bs=4
    total: nonzeros=32080896, allocated nonzeros=32080896
    total number of mallocs used during MatSetValues calls=0

 System for Energy Density starting 

IGA: dim=2 dof=1 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for Elastic Energy Density starting 

IGA: dim=2 dof=1 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for Gradient Energy Density starting 

IGA: dim=2 dof=1 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for full Stress starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 2.141786853359e+01 
  1 KSP Residual norm 4.518972244155e+00 
  2 KSP Residual norm 1.075179628246e+00 
  3 KSP Residual norm 1.583307703664e-02 
  4 KSP Residual norm 7.149001449460e-03 
  5 KSP Residual norm 3.002266728647e-03 
  6 KSP Residual norm 7.596685024480e-05 
  7 KSP Residual norm 7.946957089535e-06 
  8 KSP Residual norm 2.217469758511e-06 
  9 KSP Residual norm 1.686130795088e-06 
 10 KSP Residual norm 6.492835419954e-07 
 11 KSP Residual norm 1.460909941736e-07 
 12 KSP Residual norm 2.947981900654e-10 
 13 KSP Residual norm 1.230573725008e-10 
 14 KSP Residual norm 3.341785967283e-11 
 15 KSP Residual norm 3.544614201888e-12 
 16 KSP Residual norm 6.223161455672e-14 
 17 KSP Residual norm 4.402690530238e-14 
 18 KSP Residual norm 3.595473759726e-14 
 19 KSP Residual norm 3.114044219610e-14 
 20 KSP Residual norm 2.785436227155e-14 
 21 KSP Residual norm 2.542834674717e-14 
 22 KSP Residual norm 2.354267661673e-14 
 23 KSP Residual norm 2.202257981004e-14 
 24 KSP Residual norm 2.076339709148e-14 
 25 KSP Residual norm 1.969812310683e-14 
 26 KSP Residual norm 1.878160685039e-14 
 27 KSP Residual norm 1.798216584824e-14 
 28 KSP Residual norm 1.727682506892e-14 
 29 KSP Residual norm 1.664846346515e-14 
 30 KSP Residual norm 4.826746967490e-13 
 31 KSP Residual norm 3.431001727417e-14 
 32 KSP Residual norm 2.017568186941e-14 
 33 KSP Residual norm 1.361975702753e-14 
 34 KSP Residual norm 2.249035089846e-15 
 35 KSP Residual norm 1.301360692655e-15 
 36 KSP Residual norm 7.673963022502e-16 
 37 KSP Residual norm 2.053853583097e-16 
 38 KSP Residual norm 6.553482854396e-18 
 39 KSP Residual norm 3.427355044464e-18 
 40 KSP Residual norm 1.172650961763e-18 
 41 KSP Residual norm 1.410858248308e-20 
 42 KSP Residual norm 8.141319374782e-21 
 43 KSP Residual norm 1.005373728522e-22 
 44 KSP Residual norm 8.867448282997e-25 
Linear solve converged due to CONVERGED_RTOL iterations 44
KSP Object: 6 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-24, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=27068, cols=27068, bs=4
            package used to perform factorization: petsc
            total: nonzeros=5081840, allocated nonzeros=5081840
            total number of mallocs used during MatSetValues calls=0
                block size is 4
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=27068, cols=27068, bs=4
      total: nonzeros=5081840, allocated nonzeros=5081840
      total number of mallocs used during MatSetValues calls=0
          block size is 4
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=166464, cols=166464, bs=4
    total: nonzeros=32080896, allocated nonzeros=32080896
    total number of mallocs used during MatSetValues calls=0

 System for V-alpha starting 

IGA: dim=2 dof=2 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 0.000000000000e+00 
Linear solve converged due to CONVERGED_ATOL iterations 0
KSP Object: 6 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-10, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=13534, cols=13534, bs=2
            package used to perform factorization: petsc
            total: nonzeros=1270460, allocated nonzeros=1270460
            total number of mallocs used during MatSetValues calls=0
                block size is 2
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=13534, cols=13534, bs=2
      total: nonzeros=1270460, allocated nonzeros=1270460
      total number of mallocs used during MatSetValues calls=0
          block size is 2
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=83232, cols=83232, bs=2
    total: nonzeros=8020224, allocated nonzeros=8020224
    total number of mallocs used during MatSetValues calls=0

 System for L2 projection for exact stress starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[6] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[6] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 2.139672592922e+01 
  1 KSP Residual norm 4.804916255070e+00 
  2 KSP Residual norm 1.177123288543e+00 
  3 KSP Residual norm 2.167959447298e-02 
  4 KSP Residual norm 1.168046394438e-02 
  5 KSP Residual norm 6.056027510298e-03 
  6 KSP Residual norm 7.733166025487e-05 
  7 KSP Residual norm 1.162381257610e-05 
  8 KSP Residual norm 2.329828301588e-06 
  9 KSP Residual norm 2.899467685670e-06 
 10 KSP Residual norm 8.763677559374e-07 
 11 KSP Residual norm 2.035894466165e-07 
 12 KSP Residual norm 4.312076960199e-10 
 13 KSP Residual norm 2.326786482896e-10 
 14 KSP Residual norm 4.277751720828e-11 
 15 KSP Residual norm 5.751243683279e-12 
 16 KSP Residual norm 2.302265745992e-15 
 17 KSP Residual norm 6.442108622453e-17 
Linear solve converged due to CONVERGED_RTOL iterations 17
KSP Object: 6 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-16, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=27068, cols=27068, bs=4
            package used to perform factorization: petsc
            total: nonzeros=5081840, allocated nonzeros=5081840
            total number of mallocs used during MatSetValues calls=0
                block size is 4
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=27068, cols=27068, bs=4
      total: nonzeros=5081840, allocated nonzeros=5081840
      total number of mallocs used during MatSetValues calls=0
          block size is 4
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=166464, cols=166464, bs=4
    total: nonzeros=32080896, allocated nonzeros=32080896
    total number of mallocs used during MatSetValues calls=0

 System for L2 projection for grad(Z0) 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 4.968651113570e+00 
  1 KSP Residual norm 1.254521131446e+00 
  2 KSP Residual norm 3.686137803871e-01 
  3 KSP Residual norm 3.811337802033e-03 
  4 KSP Residual norm 1.270021154595e-03 
  5 KSP Residual norm 1.444336309199e-03 
  6 KSP Residual norm 1.385957481644e-05 
  7 KSP Residual norm 3.213836285089e-06 
  8 KSP Residual norm 3.811138336712e-07 
  9 KSP Residual norm 4.745126970154e-07 
 10 KSP Residual norm 1.457716636680e-07 
 11 KSP Residual norm 2.867021857515e-08 
 12 KSP Residual norm 7.304605178917e-11 
 13 KSP Residual norm 5.183077527674e-11 
 14 KSP Residual norm 1.232401786057e-11 
 15 KSP Residual norm 9.590323251771e-13 
 16 KSP Residual norm 4.190623015205e-16 
Linear solve converged due to CONVERGED_RTOL iterations 16
KSP Object: 6 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-16, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=27068, cols=27068, bs=4
            package used to perform factorization: petsc
            total: nonzeros=5081840, allocated nonzeros=5081840
            total number of mallocs used during MatSetValues calls=0
                block size is 4
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=27068, cols=27068, bs=4
      total: nonzeros=5081840, allocated nonzeros=5081840
      total number of mallocs used during MatSetValues calls=0
          block size is 4
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=166464, cols=166464, bs=4
    total: nonzeros=32080896, allocated nonzeros=32080896
    total number of mallocs used during MatSetValues calls=0

 System for curl part of Helmholtz of Z starting 

IGA: dim=2 dof=4 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Axis 1: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41209 min=6767 max=7038 max/min=1.04005
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for grad part of Z starting 

IGA: dim=2 dof=2 order=2 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Axis 1: basis=BSPLINE[2,1] rule=LEGENDRE[3] periodic=0 nnp=203 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41209 min=6767 max=7038 max/min=1.04005
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01

 System for GradGradz starting 

IGA: dim=2 dof=8 order=3 geometry=2 rational=0 property=0
Axis 0: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Axis 1: basis=BSPLINE[3,2] rule=LEGENDRE[4] periodic=0 nnp=204 nel=201
Partition - MPI: processors=[2,3,1] total=6
Partition - nnp: sum=41616 min=6767 max=7210 max/min=1.06546
Partition - nel: sum=40401 min=6700 max=6767 max/min=1.01
  0 KSP Residual norm 4.158898857723e+00 
  1 KSP Residual norm 7.241144437840e-01 
  2 KSP Residual norm 4.375105556778e-02 
  3 KSP Residual norm 2.484533475747e-02 
  4 KSP Residual norm 2.623292543009e-03 
  5 KSP Residual norm 1.198376728577e-04 
  6 KSP Residual norm 9.233578709030e-06 
  7 KSP Residual norm 2.479580122130e-06 
  8 KSP Residual norm 4.781975826863e-07 
  9 KSP Residual norm 3.825094034115e-07 
 10 KSP Residual norm 8.007047829638e-08 
 11 KSP Residual norm 1.560922754767e-08 
 12 KSP Residual norm 7.309594956148e-11 
 13 KSP Residual norm 5.269001603084e-12 
 14 KSP Residual norm 1.826067350162e-12 
 15 KSP Residual norm 5.910092672123e-13 
 16 KSP Residual norm 4.110739704048e-14 
 17 KSP Residual norm 2.917580157327e-14 
 18 KSP Residual norm 2.385131522169e-14 
 19 KSP Residual norm 2.066859785754e-14 
 20 KSP Residual norm 1.849341031139e-14 
 21 KSP Residual norm 1.688627193933e-14 
 22 KSP Residual norm 1.563641284742e-14 
 23 KSP Residual norm 1.462846413272e-14 
 24 KSP Residual norm 1.379327077703e-14 
 25 KSP Residual norm 1.308652553540e-14 
 26 KSP Residual norm 1.247835516558e-14 
 27 KSP Residual norm 1.194778792941e-14 
 28 KSP Residual norm 1.147961008491e-14 
 29 KSP Residual norm 1.106248072225e-14 
 30 KSP Residual norm 6.237471363279e-14 
 31 KSP Residual norm 2.061523613286e-14 
 32 KSP Residual norm 8.540197182509e-15 
 33 KSP Residual norm 3.522497482721e-15 
 34 KSP Residual norm 2.674575250244e-15 
 35 KSP Residual norm 8.788720329214e-16 
 36 KSP Residual norm 4.873438589894e-16 
 37 KSP Residual norm 9.895504995610e-17 
 38 KSP Residual norm 5.994306916292e-18 
 39 KSP Residual norm 1.571630976781e-18 
 40 KSP Residual norm 4.137017709818e-19 
 41 KSP Residual norm 5.026722707198e-21 
 42 KSP Residual norm 8.058553489708e-22 
 43 KSP Residual norm 4.329759488413e-23 
 44 KSP Residual norm 1.150935100654e-24 
Linear solve converged due to CONVERGED_RTOL iterations 44
KSP Object: 6 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-24, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 6 MPI processes
  type: bjacobi
    number of blocks = 6
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqbaij
            rows=54136, cols=54136, bs=8
            package used to perform factorization: petsc
            total: nonzeros=20327360, allocated nonzeros=20327360
            total number of mallocs used during MatSetValues calls=0
                block size is 8
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqbaij
      rows=54136, cols=54136, bs=8
      total: nonzeros=20327360, allocated nonzeros=20327360
      total number of mallocs used during MatSetValues calls=0
          block size is 8
  linear system matrix = precond matrix:
  Mat Object: 6 MPI processes
    type: mpibaij
    rows=332928, cols=332928, bs=8
    total: nonzeros=128323584, allocated nonzeros=128323584
    total number of mallocs used during MatSetValues calls=0
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


./PruebaV5S on a arch-linux2-c-debug named zegpi-acer with 6 processors, by eazegpi Mon Apr  6 21:22:40 2020
Using Petsc Release Version 3.12.4, unknown 

                         Max       Max/Min     Avg       Total 
Time (sec):           7.639e+02     1.000   7.639e+02
Objects:              2.153e+03     1.000   2.153e+03
Flop:                 6.031e+11     1.606   4.676e+11  2.806e+12
Flop/sec:             7.896e+08     1.606   6.122e+08  3.673e+09
Memory:               4.569e+08     1.057   4.418e+08  2.651e+09
MPI Messages:         5.910e+03     1.526   4.591e+03  2.754e+04
MPI Message Lengths:  1.180e+08     1.647   1.854e+04  5.107e+08
MPI Reductions:       2.803e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total 
 0:      Main Stage: 7.6386e+02 100.0%  2.8056e+12 100.0%  2.754e+04 100.0%  1.854e+04      100.0%  2.802e+04 100.0% 

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------


      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided        151 1.0 2.4025e-02 1.1 0.00e+00 0.0 6.8e+02 4.0e+00 0.0e+00  0  0  2  0  0   0  0  2  0  0     0
BuildTwoSidedF       122 1.0 4.6963e-01 2.7 0.00e+00 0.0 8.8e+02 3.2e+05 0.0e+00  0  0  3 55  0   0  0  3 55  0     0
PCSetUp               29 1.0 1.4612e+02 1.0 7.62e+09 1.1 0.0e+00 0.0e+00 2.1e+02 19  2  0  0  1  19  2  0  0  1   303
PCSetUpOnBlocks       10 1.0 4.8678e+00 1.1 7.45e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0  8817
PCApply              817 1.0 1.1318e+01 1.0 5.76e+11 1.7 1.0e+03 3.4e+04 1.7e+02  1 94  4  7  1   1 94  4  7  1 233535
MatMult              816 1.0 9.2232e+00 1.1 7.00e+09 1.1 1.8e+04 4.4e+03 0.0e+00  1  1 65 15  0   1  1 65 15  0  4424
MatSolve             817 1.0 1.1246e+01 1.0 5.76e+11 1.7 1.0e+03 3.4e+04 1.7e+02  1 94  4  7  1   1 94  4  7  1 235017
MatLUFactorSym         9 1.0 1.2725e+01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 3.6e+01  2  0  0  0  0   2  0  0  0  0     0
MatLUFactorNum        19 1.0 1.3297e+02 1.0 7.62e+09 1.1 0.0e+00 0.0e+00 0.0e+00 17  2  0  0  0  17  2  0  0  0   333
MatILUFactorSym       10 1.0 3.7189e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin      44 1.0 1.0741e+0217.1 0.00e+00 0.0 3.9e+02 7.1e+05 1.5e+02 11  0  1 55  1  11  0  1 55  1     0
MatAssemblyEnd        44 1.0 1.0195e+00 1.1 5.41e+04 0.0 7.5e+02 1.1e+03 7.2e+02  0  0  3  0  3   0  0  3  0  3     0
MatGetRowIJ           13 1.0 8.8215e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering        13 1.0 1.5612e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         1 1.0 8.9028e-03 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatView               27 3.0 2.0013e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 1.8e+01  0  0  0  0  0   0  0  0  0  0     0
IGAFormSystem          1 1.0 6.0807e+00 1.0 2.04e+09 1.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0  1997
VecView               19 1.0 1.1182e-01 1.0 0.00e+00 0.0 9.5e+01 1.9e+05 1.9e+01  0  0  0  4  0   0  0  0  4  0     0
VecMDot              761 1.0 7.2863e-01 1.0 6.41e+08 1.0 0.0e+00 0.0e+00 1.5e+03  0  0  0  0  5   0  0  0  0  5  5130
VecTDot               66 1.0 7.8044e-02 4.2 3.81e+06 1.1 0.0e+00 0.0e+00 1.3e+02  0  0  0  0  0   0  0  0  0  0   282
VecNorm             1634 1.0 3.6107e-01 1.4 9.54e+07 1.0 0.0e+00 0.0e+00 1.7e+03  0  0  0  0  6   0  0  0  0  6  1540
VecScale             799 1.0 3.9249e-02 1.1 2.32e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  3455
VecCopy               26 1.0 1.4358e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               934 1.0 1.0751e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              110 1.0 9.2268e-03 1.1 6.20e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  3896
VecAYPX               31 1.0 2.9109e-03 1.3 1.79e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  3546
VecWAXPY              17 1.0 2.1734e-03 1.1 4.79e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  1289
VecMAXPY             799 1.0 5.8701e-01 1.1 6.85e+08 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  6810
VecAssemblyBegin      46 1.0 1.5374e-01 3.2 0.00e+00 0.0 4.9e+02 1.9e+03 9.2e+01  0  0  2  0  0   0  0  2  0  0     0
VecAssemblyEnd        46 1.0 5.7054e-04 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecLoad               22 1.0 1.3106e-01 1.0 0.00e+00 0.0 1.1e+02 1.8e+05 9.2e+01  0  0  0  4  0   0  0  0  4  0     0
VecScatterBegin      949 1.0 6.9582e-02 1.2 0.00e+00 0.0 1.9e+04 6.6e+03 1.8e+01  0  0 69 25  0   0  0 69 25  0     0
VecScatterEnd        949 1.0 5.4226e-02 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecNormalize         248 1.0 1.0615e-01 1.3 2.32e+07 1.1 0.0e+00 0.0e+00 5.0e+02  0  0  0  0  2   0  0  0  0  2  1262
SFSetGraph           151 1.0 5.1265e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp              160 1.0 1.3737e-01 1.0 0.00e+00 0.0 2.0e+03 4.7e+03 0.0e+00  0  0  7  2  0   0  0  7  2  0     0
SFBcastOpBegin       929 1.0 6.2852e-02 1.3 0.00e+00 0.0 1.9e+04 6.1e+03 1.8e+01  0  0 69 23  0   0  0 69 23  0     0
SFBcastOpEnd         929 1.0 4.9719e-02 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFReduceBegin         20 1.0 4.1752e-03 1.1 0.00e+00 0.0 1.2e+02 8.2e+04 0.0e+00  0  0  0  2  0   0  0  0  2  0     0
SFReduceEnd           20 1.0 1.0412e-03 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp              29 1.0 2.6911e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve              19 1.0 1.6999e+02 1.0 5.92e+11 1.6 1.9e+04 6.0e+03 1.9e+04 22 98 69 22 69  22 98 69 22 69 16098
KSPGMRESOrthog       761 1.0 3.6394e+00 1.3 1.28e+09 1.0 0.0e+00 0.0e+00 1.6e+04  0  0  0  0 56   0  0  0  0 56  2054
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

                 IGA    20              1         1224     0.
      Preconditioner    29             28        27120     0.
    Distributed Mesh     9              9        44136     0.
              Matrix    79             75  55340232222153089024     0.
           Index Set   659            638     10136356     0.
   IS L to G Mapping    59             40      1177888     0.
              Viewer    52             51        42840     0.
         Vec Scatter   160             81        64152     0.
              Vector   830            777    101552288     0.
   Star Forest Graph   178             99        95960     0.
   Application Order    40             21      1172896     0.
       Krylov Solver    29             28       315736     0.
     Discrete System     9              9         8496     0.
========================================================================================================================
Average time to get PetscTime(): 2.38419e-08
Average time for MPI_Barrier(): 5.74589e-05
Average time for zero size MPI_Send(): 1.21593e-05
#PETSc Option Table entries:
-iga_view
-ksp_converged_reason
-ksp_monitor
-ksp_view
-log_view
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-cc=gcc --with-fc=gfortran --download-mpich --download-fblaslapack --download-scalapack --download-mumps --download-parmetis --download-metis --download-ptscotch --download-hypre --download-ml --download-cmake
-----------------------------------------
Libraries compiled on 2020-03-02 20:59:08 on zegpi-acer 
Machine characteristics: Linux-5.3.0-40-generic-x86_64-with-Ubuntu-18.04-bionic
Using PETSc directory: /home/eazegpi/petsc
Using PETSc arch: arch-linux2-c-debug
-----------------------------------------

Using C compiler: /home/eazegpi/petsc/arch-linux2-c-debug/bin/mpicc  -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g3  
Using Fortran compiler: /home/eazegpi/petsc/arch-linux2-c-debug/bin/mpif90  -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g   
-----------------------------------------

Using include paths: -I/home/eazegpi/petsc/include -I/home/eazegpi/petsc/arch-linux2-c-debug/include
-----------------------------------------

Using C linker: /home/eazegpi/petsc/arch-linux2-c-debug/bin/mpicc
Using Fortran linker: /home/eazegpi/petsc/arch-linux2-c-debug/bin/mpif90
Using libraries: -Wl,-rpath,/home/eazegpi/petsc/arch-linux2-c-debug/lib -L/home/eazegpi/petsc/arch-linux2-c-debug/lib -lpetsc -Wl,-rpath,/home/eazegpi/petsc/arch-linux2-c-debug/lib -L/home/eazegpi/petsc/arch-linux2-c-debug/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lml -lflapack -lfblas -lptesmumps -lptscotchparmetis -lptscotch -lptscotcherr -lesmumps -lscotch -lscotcherr -lpthread -lparmetis -lmetis -lm -lstdc++ -ldl -lmpifort -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lrt -lstdc++ -ldl
-----------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


